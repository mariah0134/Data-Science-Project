{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "okNeEix1jBXh",
        "T5xgP1u0Kfmp",
        "lDA50PgRjcMY",
        "d2SlAauPjlb6"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgvgbFhWzvYB2acESJ36Ia",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariah0134/Data-Science-Project/blob/main/Notebooks/Phase-3/models_and_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Objective Metrics"
      ],
      "metadata": {
        "id": "okNeEix1jBXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "gt_file = \"test_set_ground_truth (1).csv\"   # ground truth\n",
        "model_file = \"model_a_results (1).csv\"      # baseline results\n",
        "\n",
        "gt = pd.read_csv(gt_file)\n",
        "model = pd.read_csv(model_file)\n",
        "\n",
        "print(\"Ground Truth columns:\", gt.columns)\n",
        "print(\"Model columns:\", model.columns)\n",
        "\n",
        "\n",
        "\n",
        "# ===== 2) توحيد صيغة السؤال والدمج =====\n",
        "def normalize_question(s):\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    return \" \".join(s.strip().split())\n",
        "\n",
        "gt[\"question_norm\"] = gt[\"Question\"].apply(normalize_question)\n",
        "model[\"question_norm\"] = model[\"question\"].apply(normalize_question)\n",
        "\n",
        "merged = pd.merge(\n",
        "    model,\n",
        "    gt[[\"question_norm\", \"Question\", \"Answer\", \"Source\", \"Topic\"]],\n",
        "    on=\"question_norm\",\n",
        "    how=\"inner\",\n",
        ")\n",
        "\n",
        "print(\"عدد الأسئلة بعد الدمج:\", len(merged))\n",
        "\n",
        "\n",
        "# ===== 3) دوال التوكن والـ Overlap =====\n",
        "def simple_tokenize_ar(s):\n",
        "    if not isinstance(s, str):\n",
        "        return []\n",
        "    s = s.replace(\"،\", \" \").replace(\"؟\", \" \").replace(\"ـ\", \" \")\n",
        "    s = re.sub(r\"[^\\w\\s\\u0600-\\u06FF]\", \" \", s)\n",
        "    return [t for t in s.split() if t]\n",
        "\n",
        "def overlap_scores(gold_answer, pred_text):\n",
        "    \"\"\"\n",
        "    بين الجواب الصحيح (Answer) وبين النص اللي رجعه الـbaseline (chunk)\n",
        "    \"\"\"\n",
        "    if not isinstance(gold_answer, str) or not isinstance(pred_text, str):\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    gold_tokens = simple_tokenize_ar(gold_answer)\n",
        "    pred_tokens = simple_tokenize_ar(pred_text)\n",
        "\n",
        "    if not gold_tokens or not pred_tokens:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    set_gold = set(gold_tokens)\n",
        "    set_pred = set(pred_tokens)\n",
        "\n",
        "    inter = set_gold & set_pred\n",
        "    union = set_gold | set_pred\n",
        "\n",
        "    jaccard = len(inter) / len(union) if union else 0.0\n",
        "    coverage_pred_in_gold = len(inter) / len(set_pred) if set_pred else 0.0\n",
        "    coverage_gold_in_pred = len(inter) / len(set_gold) if set_gold else 0.0\n",
        "\n",
        "    return jaccard, coverage_pred_in_gold, coverage_gold_in_pred\n",
        "\n",
        "\n",
        "# ===== 4) حساب المقاييس لـ top1 / top2 / top3 =====\n",
        "j1_list, c1_list, c1g_list = [], [], []\n",
        "j2_list, c2_list, c2g_list = [], [], []\n",
        "j3_list, c3_list, c3g_list = [], [], []\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    gold = row[\"Answer\"]\n",
        "\n",
        "    j1, c1, c1g = overlap_scores(gold, row[\"top_retrieved_chunk\"])\n",
        "    j2, c2, c2g = overlap_scores(gold, row[\"top_2_retrieved_chunk\"])\n",
        "    j3, c3, c3g = overlap_scores(gold, row[\"top_3_retrieved_chunk\"])\n",
        "\n",
        "    j1_list.append(j1); c1_list.append(c1); c1g_list.append(c1g)\n",
        "    j2_list.append(j2); c2_list.append(c2); c2g_list.append(c2g)\n",
        "    j3_list.append(j3); c3_list.append(c3); c3g_list.append(c3g)\n",
        "\n",
        "merged[\"Jaccard_top1\"] = j1_list\n",
        "merged[\"Coverage_top1_AnsInChunk\"] = c1_list\n",
        "merged[\"Coverage_top1_ChunkInAns\"] = c1g_list\n",
        "\n",
        "merged[\"Jaccard_top2\"] = j2_list\n",
        "merged[\"Coverage_top2_AnsInChunk\"] = c2_list\n",
        "merged[\"Coverage_top2_ChunkInAns\"] = c2g_list\n",
        "\n",
        "merged[\"Jaccard_top3\"] = j3_list\n",
        "merged[\"Coverage_top3_AnsInChunk\"] = c3_list\n",
        "merged[\"Coverage_top3_ChunkInAns\"] = c3g_list\n",
        "\n",
        "\n",
        "# ===== 5) أفضل نتيجة من الثلاثة (baseline@k) =====\n",
        "merged[\"Best_Jaccard\"] = merged[[\"Jaccard_top1\", \"Jaccard_top2\", \"Jaccard_top3\"]].max(axis=1)\n",
        "merged[\"Best_Coverage_AnsInChunk\"] = merged[\n",
        "    [\"Coverage_top1_AnsInChunk\", \"Coverage_top2_AnsInChunk\", \"Coverage_top3_AnsInChunk\"]\n",
        "].max(axis=1)\n",
        "\n",
        "\n",
        "# ===== 6) (اختياري) Correctness أوتوماتي تقريبي للـBaseline =====\n",
        "def auto_correctness(cov):\n",
        "    if cov >= 0.60:\n",
        "        return 2\n",
        "    elif cov >= 0.30:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "merged[\"Baseline_Correctness_auto\"] = merged[\"Best_Coverage_AnsInChunk\"].apply(auto_correctness)\n",
        "\n",
        "\n",
        "# ===== 7) ملخص سريع للمقاييس =====\n",
        "print(\"\\n========== Baseline Metrics (Using Answer vs Retrieved Chunk) ==========\")\n",
        "print(f\"Average Jaccard (Top-1): {merged['Jaccard_top1'].mean():.3f}\")\n",
        "print(f\"Average Jaccard (Best of Top-3): {merged['Best_Jaccard'].mean():.3f}\")\n",
        "print(f\"Average Coverage Answer in Chunk (Top-1): {merged['Coverage_top1_AnsInChunk'].mean():.3f}\")\n",
        "print(f\"Average Coverage Answer in Chunk (Best of Top-3): {merged['Best_Coverage_AnsInChunk'].mean():.3f}\")\n",
        "print(f\"Average Baseline_Correctness_auto: {merged['Baseline_Correctness_auto'].mean():.3f}\")\n",
        "\n",
        "\n",
        "# ===== 8) حفظ ملف جاهز للمقارنة =====\n",
        "out_path = \"baseline_evaluation_metrics.csv\"\n",
        "merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"\\nتم حفظ ملف التقييم الكامل للبيس لاين في:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT38v2NThEiS",
        "outputId": "194b2b4f-4365-447c-e7ce-af48181e2546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth columns: Index(['Question', 'Answer', 'Source', 'Topic'], dtype='object')\n",
            "Model columns: Index(['question', 'top_retrieved_chunk', 'top_2_retrieved_chunk',\n",
            "       'top_3_retrieved_chunk'],\n",
            "      dtype='object')\n",
            "عدد الأسئلة بعد الدمج: 65\n",
            "\n",
            "========== Baseline Metrics (Using Answer vs Retrieved Chunk) ==========\n",
            "Average Jaccard (Top-1): 0.049\n",
            "Average Jaccard (Best of Top-3): 0.060\n",
            "Average Coverage Answer in Chunk (Top-1): 0.060\n",
            "Average Coverage Answer in Chunk (Best of Top-3): 0.077\n",
            "Average Baseline_Correctness_auto: 0.000\n",
            "\n",
            "تم حفظ ملف التقييم الكامل للبيس لاين في: baseline_evaluation_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV9pnR-sEDff",
        "outputId": "382d299c-3ec7-46e6-e1b1-65b7fc7c1c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "أعمدة BOE: Index(['Section', 'Chapter', 'Article', 'Text', 'Status', 'Source'], dtype='object')\n",
            "أعمدة Gemini: Index(['المادة القانونية (م)', 'السؤال', 'الإجابة'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# غيّري الأسماء هنا إذا ملفاتك مختلفة\n",
        "boe_filename = \"boe_cleaned (5).csv\"\n",
        "zero_filename = \"zero-shot(geminiQ-A).xlsx\"\n",
        "\n",
        "# قراءة الملفات\n",
        "boe = pd.read_csv(boe_filename)\n",
        "zero = pd.read_excel(zero_filename)\n",
        "\n",
        "# نتأكد من الأسماء\n",
        "print(\"أعمدة BOE:\", boe.columns)\n",
        "print(\"أعمدة Gemini:\", zero.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#zero-shot"
      ],
      "metadata": {
        "id": "T5xgP1u0Kfmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalize_article_label(s):\n",
        "    \"\"\"\n",
        "    تنظيف اسم المادة:\n",
        "    - إزالة كلمة (المادة)\n",
        "    - حذف الرموز الزائدة\n",
        "    - توحيد المسافات\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return None\n",
        "    s = s.strip()\n",
        "    s = s.replace(\"المادة\", \"\")\n",
        "    s = s.strip(\" :-؟:.\")\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "boe[\"Article_label\"] = boe[\"Article\"].apply(normalize_article_label)\n",
        "\n",
        "\n",
        "zero[\"Article_label\"] = zero[\"المادة القانونية (م)\"].apply(normalize_article_label)\n",
        "\n",
        "\n",
        "merged = pd.merge(\n",
        "    zero,\n",
        "    boe[[\"Article\", \"Text\", \"Article_label\"]],\n",
        "    on=\"Article_label\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_boe\")\n",
        ")\n",
        "\n",
        "# نعيد تسمية أعمدة الذهبية\n",
        "merged[\"Gold_Article\"] = merged[\"Article\"]\n",
        "merged[\"Gold_Text\"] = merged[\"Text\"]\n",
        "\n",
        "print(\"عدد الصفوف بعد الدمج:\", len(merged))\n",
        "print(\"عدد الصفوف اللي ما لها Gold_Article:\", merged[\"Gold_Article\"].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWmdvtzBEHI-",
        "outputId": "c2ad522f-c14d-4531-e4fb-c64ac089316a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عدد الصفوف بعد الدمج: 267\n",
            "عدد الصفوف اللي ما لها Gold_Article: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "=====\n",
        "\n",
        "def simple_tokenize_ar(s):\n",
        "    \"\"\"\n",
        "    تقسيم النص العربي إلى كلمات بسيطة،\n",
        "    مع إزالة علامات الترقيم والرموز.\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return []\n",
        "    s = s.replace(\"،\", \" \").replace(\"؟\", \" \").replace(\"ـ\", \" \")\n",
        "\n",
        "    s = re.sub(r\"[^\\w\\s\\u0600-\\u06FF]\", \" \", s)\n",
        "    tokens = [t for t in s.split() if t]\n",
        "    return tokens\n",
        "\n",
        "def overlap_scores(article_text, answer_text):\n",
        "    \"\"\"\n",
        "    ترجع:\n",
        "    - Jaccard overlap بين كلمات المادة والجواب\n",
        "    - Coverage Answer in Article\n",
        "    - Coverage Article in Answer\n",
        "    \"\"\"\n",
        "    if not isinstance(article_text, str) or not isinstance(answer_text, str):\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    art_tokens = simple_tokenize_ar(article_text)\n",
        "    ans_tokens = simple_tokenize_ar(answer_text)\n",
        "\n",
        "    if not art_tokens or not ans_tokens:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    set_art = set(art_tokens)\n",
        "    set_ans = set(ans_tokens)\n",
        "\n",
        "    inter = set_art.intersection(set_ans)\n",
        "    union = set_art.union(set_ans)\n",
        "\n",
        "    jaccard = len(inter) / len(union) if union else 0.0\n",
        "    coverage_answer_in_article = len(inter) / len(set_ans) if set_ans else 0.0\n",
        "    coverage_article_in_answer = len(inter) / len(set_art) if set_art else 0.0\n",
        "\n",
        "    return jaccard, coverage_answer_in_article, coverage_article_in_answer"
      ],
      "metadata": {
        "id": "-xg5Ji3vEIwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "jaccards = []\n",
        "cov_answer = []\n",
        "cov_article = []\n",
        "\n",
        "for idx, row in merged.iterrows():\n",
        "    j, ca, ct = overlap_scores(row.get(\"Gold_Text\"), row.get(\"الإجابة\"))\n",
        "    jaccards.append(j)\n",
        "    cov_answer.append(ca)\n",
        "    cov_article.append(ct)\n",
        "\n",
        "merged[\"Overlap_Jaccard\"] = jaccards\n",
        "merged[\"Coverage_Answer_in_Article\"] = cov_answer\n",
        "merged[\"Coverage_Article_in_Answer\"] = cov_article\n",
        "\n",
        "# أطوال النصوص\n",
        "merged[\"Answer_Length_Tokens\"] = merged[\"الإجابة\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "merged[\"Article_Length_Tokens\"] = merged[\"Gold_Text\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "\n",
        "print(\"تم حساب المقاييس.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gklxW7zH0Ae",
        "outputId": "d2a0c7a5-9d98-45f4-8302-7b43c9e8b9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم حساب المقاييس.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merged[\"Manual_Correctness\"] = \"\"\n",
        "merged[\"Manual_Grammar\"] = \"\"\n",
        "merged[\"Manual_Style\"] = \"\"\n",
        "merged[\"Relevance\"] = \"\"\n",
        "merged[\"Notes\"] = \"\"\n",
        "\n",
        "def apply_hard_rules(row):\n",
        "    art_lbl = row[\"Article_label\"]\n",
        "    notes = []\n",
        "    manual_correctness = \"\"\n",
        "\n",
        "    if isinstance(art_lbl, str):\n",
        "        if \"الثامنة\" in art_lbl:\n",
        "            manual_correctness = 0\n",
        "            notes.append(\"إحالة خاطئة: المادة الصحيحة للّغة هي التاسعة.\")\n",
        "        if \"مائة وواحد\" in art_lbl:\n",
        "            manual_correctness = 0\n",
        "            notes.append(\"إحالة خاطئة: فترات الراحة في المادة 102.\")\n",
        "        if \"مائة وسبعة\" in art_lbl:\n",
        "            manual_correctness = 0\n",
        "            notes.append(\"المادة 107 ملغاة، لا يُستند إليها.\")\n",
        "\n",
        "    return manual_correctness, \" | \".join(notes)\n",
        "\n",
        "mc_list = []\n",
        "notes_list = []\n",
        "\n",
        "for idx, row in merged.iterrows():\n",
        "    mc, note = apply_hard_rules(row)\n",
        "    mc_list.append(mc)\n",
        "    notes_list.append(note)\n",
        "\n",
        "merged[\"Manual_Correctness\"] = mc_list\n",
        "merged[\"Notes\"] = notes_list\n",
        "\n",
        "print(\"تم تطبيق القواعد الخاصة للمقالات (8/9، 101/102، 107).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d68djxuZH9YU",
        "outputId": "2964d89c-c9e7-4d8a-9d54-f42f01afaa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تطبيق القواعد الخاصة للمقالات (8/9، 101/102، 107).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "out_filename = \"zero_shot_evaluation_full.csv\"\n",
        "merged.to_csv(out_filename, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"تم حفظ ملف التقييم في:\", out_filename)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(out_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxYT9jfyIB05",
        "outputId": "ad2df1af-b87d-42fc-9b38-930e6af55822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم حفظ ملف التقييم في: zero_shot_evaluation_full.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_afca27e7-5009-4119-960b-c6ca4e2e5dec\", \"zero_shot_evaluation_full.csv\", 446618)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#one-shot"
      ],
      "metadata": {
        "id": "lDA50PgRjcMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "boe_filename = \"boe_cleaned (5).csv\"\n",
        "one_filename = \"one-shot(gemini-Q-A).xlsx\"\n",
        "\n",
        "\n",
        "boe = pd.read_csv(boe_filename)\n",
        "one = pd.read_excel(one_filename)\n",
        "\n",
        "# ===== 2) توحيد اسم المادة والدمج =====\n",
        "def normalize_article_label(s):\n",
        "    if not isinstance(s, str):\n",
        "        return None\n",
        "    s = s.strip()\n",
        "    s = s.replace(\"المادة\", \"\")\n",
        "    s = s.strip(\" :-؟:.\")\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "boe[\"Article_label\"] = boe[\"Article\"].apply(normalize_article_label)\n",
        "one[\"Article_label\"] = one[\"المادة القانونية (م)\"].apply(normalize_article_label)\n",
        "\n",
        "merged = pd.merge(\n",
        "    one,\n",
        "    boe[[\"Article\", \"Text\", \"Article_label\"]],\n",
        "    on=\"Article_label\",\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "merged[\"Gold_Article\"] = merged[\"Article\"]\n",
        "merged[\"Gold_Text\"] = merged[\"Text\"]\n",
        "\n",
        "\n",
        "def simple_tokenize_ar(s):\n",
        "    if not isinstance(s, str):\n",
        "        return []\n",
        "    s = s.replace(\"،\", \" \").replace(\"؟\", \" \").replace(\"ـ\", \" \")\n",
        "    s = re.sub(r\"[^\\w\\s\\u0600-\\u06FF]\", \" \", s)\n",
        "    return [t for t in s.split() if t]\n",
        "\n",
        "def overlap_scores(article_text, answer_text):\n",
        "    if not isinstance(article_text, str) or not isinstance(answer_text, str):\n",
        "        return 0.0, 0.0, 0.0\n",
        "    art_tokens = simple_tokenize_ar(article_text)\n",
        "    ans_tokens = simple_tokenize_ar(answer_text)\n",
        "    if not art_tokens or not ans_tokens:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    set_art = set(art_tokens)\n",
        "    set_ans = set(ans_tokens)\n",
        "    inter = set_art & set_ans\n",
        "    union = set_art | set_ans\n",
        "    jaccard = len(inter) / len(union) if union else 0.0\n",
        "    cov_ans = len(inter) / len(set_ans) if set_ans else 0.0\n",
        "    cov_art = len(inter) / len(set_art) if set_art else 0.0\n",
        "    return jaccard, cov_ans, cov_art\n",
        "\n",
        "j_list, cov_ans_list, cov_art_list = [], [], []\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    j, ca, ct = overlap_scores(row[\"Gold_Text\"], row[\"الإجابة\"])\n",
        "    j_list.append(j)\n",
        "    cov_ans_list.append(ca)\n",
        "    cov_art_list.append(ct)\n",
        "\n",
        "merged[\"Overlap_Jaccard\"] = j_list\n",
        "merged[\"Coverage_Answer_in_Article\"] = cov_ans_list\n",
        "merged[\"Coverage_Article_in_Answer\"] = cov_art_list\n",
        "\n",
        "merged[\"Answer_Length_Tokens\"] = merged[\"الإجابة\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "merged[\"Article_Length_Tokens\"] = merged[\"Gold_Text\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "\n",
        "\n",
        "n = len(merged)\n",
        "avg_jaccard = merged[\"Overlap_Jaccard\"].mean()\n",
        "avg_cov_ans = merged[\"Coverage_Answer_in_Article\"].mean()\n",
        "\n",
        "print(\"\\n========== One-Shot Objective Metrics ==========\")\n",
        "print(\"Number of One-Shot Q&A pairs:\", n)\n",
        "print(\"-\" * 50)\n",
        "print(f\"Average Overlap Jaccard            : {avg_jaccard:.3f}\")\n",
        "print(f\"Average Coverage Answer in Article : {avg_cov_ans:.3f}\")\n",
        "\n",
        "cols_to_keep = [\n",
        "    \"المادة القانونية (م)\",\n",
        "    \"السؤال\",\n",
        "    \"الإجابة\",\n",
        "    \"Gold_Article\",\n",
        "    \"Gold_Text\",\n",
        "    \"Overlap_Jaccard\",\n",
        "    \"Coverage_Answer_in_Article\",\n",
        "    \"Coverage_Article_in_Answer\",\n",
        "    \"Answer_Length_Tokens\",\n",
        "    \"Article_Length_Tokens\",\n",
        "]\n",
        "\n",
        "final_df = merged[cols_to_keep]\n",
        "\n",
        "out_path = \"one_shot_metrics_clean.csv\"\n",
        "final_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"\\nتم حفظ الملف النظيف بدون أي Manual أو Relevance باسم:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctx9mmaxKksn",
        "outputId": "ad78384d-0d7c-4bfb-c640-e354ff83e97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== One-Shot Objective Metrics ==========\n",
            "Number of One-Shot Q&A pairs: 207\n",
            "--------------------------------------------------\n",
            "Average Overlap Jaccard            : 0.148\n",
            "Average Coverage Answer in Article : 0.322\n",
            "\n",
            "تم حفظ الملف النظيف بدون أي Manual أو Relevance باسم: one_shot_metrics_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#three-shot"
      ],
      "metadata": {
        "id": "d2SlAauPjlb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "boe_filename = \"boe_cleaned (5).csv\"\n",
        "three_filename = \"three-shot(gemini-Q-A).xlsx\"\n",
        "\n",
        "\n",
        "boe = pd.read_csv(boe_filename)\n",
        "three = pd.read_excel(three_filename)\n",
        "\n",
        "print(\"أعمدة BOE:\", boe.columns)\n",
        "print(\"أعمدة Three-Shot:\", three.columns)\n",
        "\n",
        "\n",
        "\n",
        "# ===== 2) توحيد اسم المادة والدمج =====\n",
        "def normalize_article_label(s):\n",
        "    if not isinstance(s, str):\n",
        "        return None\n",
        "    s = s.strip()\n",
        "    s = s.replace(\"المادة\", \"\")\n",
        "    s = s.strip(\" :-؟:.\")\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "boe[\"Article_label\"] = boe[\"Article\"].apply(normalize_article_label)\n",
        "three[\"Article_label\"] = three[\"المادة القانونية (م)\"].apply(normalize_article_label)\n",
        "\n",
        "merged = pd.merge(\n",
        "    three,\n",
        "    boe[[\"Article\", \"Text\", \"Article_label\"]],\n",
        "    on=\"Article_label\",\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "merged[\"Gold_Article\"] = merged[\"Article\"]\n",
        "merged[\"Gold_Text\"] = merged[\"Text\"]\n",
        "\n",
        "print(\"عدد أزواج السؤال/الجواب بعد الدمج:\", len(merged))\n",
        "print(\"عدد الصفوف بدون مادة مطابقة:\", merged[\"Gold_Article\"].isna().sum())\n",
        "\n",
        "\n",
        "# ===== 3) دوال التوكن والـ overlap =====\n",
        "def simple_tokenize_ar(s):\n",
        "    if not isinstance(s, str):\n",
        "        return []\n",
        "    s = s.replace(\"،\", \" \").replace(\"؟\", \" \").replace(\"ـ\", \" \")\n",
        "    s = re.sub(r\"[^\\w\\s\\u0600-\\u06FF]\", \" \", s)\n",
        "    return [t for t in s.split() if t]\n",
        "\n",
        "def overlap_scores(article_text, answer_text):\n",
        "    if not isinstance(article_text, str) or not isinstance(answer_text, str):\n",
        "        return 0.0, 0.0, 0.0\n",
        "    art_tokens = simple_tokenize_ar(article_text)\n",
        "    ans_tokens = simple_tokenize_ar(answer_text)\n",
        "    if not art_tokens or not ans_tokens:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    set_art = set(art_tokens)\n",
        "    set_ans = set(ans_tokens)\n",
        "    inter = set_art & set_ans\n",
        "    union = set_art | set_ans\n",
        "\n",
        "    jaccard = len(inter) / len(union) if union else 0.0\n",
        "    cov_ans = len(inter) / len(set_ans) if set_ans else 0.0\n",
        "    cov_art = len(inter) / len(set_art) if set_art else 0.0\n",
        "    return jaccard, cov_ans, cov_art\n",
        "\n",
        "j_list, cov_ans_list, cov_art_list = [], [], []\n",
        "\n",
        "for _, row in merged.iterrows():\n",
        "    j, ca, ct = overlap_scores(row[\"Gold_Text\"], row[\"الإجابة\"])\n",
        "    j_list.append(j)\n",
        "    cov_ans_list.append(ca)\n",
        "    cov_art_list.append(ct)\n",
        "\n",
        "merged[\"Overlap_Jaccard\"] = j_list\n",
        "merged[\"Coverage_Answer_in_Article\"] = cov_ans_list\n",
        "merged[\"Coverage_Article_in_Answer\"] = cov_art_list\n",
        "\n",
        "merged[\"Answer_Length_Tokens\"] = merged[\"الإجابة\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "merged[\"Article_Length_Tokens\"] = merged[\"Gold_Text\"].apply(\n",
        "    lambda s: len(simple_tokenize_ar(s))\n",
        ")\n",
        "\n",
        "\n",
        "# ===== 4) (اختياري) نحسب المتوسطات للطباعة بس =====\n",
        "n = len(merged)\n",
        "avg_jaccard = merged[\"Overlap_Jaccard\"].mean()\n",
        "avg_cov_ans = merged[\"Coverage_Answer_in_Article\"].mean()\n",
        "\n",
        "print(\"\\n========== Three-Shot Objective Metrics ==========\")\n",
        "print(\"Number of Three-Shot Q&A pairs:\", n)\n",
        "print(\"-\" * 50)\n",
        "print(f\"Average Overlap Jaccard            : {avg_jaccard:.3f}\")\n",
        "print(f\"Average Coverage Answer in Article : {avg_cov_ans:.3f}\")\n",
        "\n",
        "\n",
        "\n",
        "cols_to_keep = [\n",
        "    \"المادة القانونية (م)\",\n",
        "    \"السؤال\",\n",
        "    \"الإجابة\",\n",
        "    \"Gold_Article\",\n",
        "    \"Gold_Text\",\n",
        "    \"Overlap_Jaccard\",\n",
        "    \"Coverage_Answer_in_Article\",\n",
        "    \"Coverage_Article_in_Answer\",\n",
        "    \"Answer_Length_Tokens\",\n",
        "    \"Article_Length_Tokens\",\n",
        "]\n",
        "\n",
        "final_df = merged[cols_to_keep]\n",
        "\n",
        "out_path = \"three_shot_metrics_clean.csv\"\n",
        "final_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"\\nتم حفظ الملف النظيف بدون أي Manual باسم:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK5fK2EwdAXb",
        "outputId": "a61a9976-fbcf-4e84-feae-cfb1c0dc101e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "أعمدة BOE: Index(['Section', 'Chapter', 'Article', 'Text', 'Status', 'Source'], dtype='object')\n",
            "أعمدة Three-Shot: Index(['المادة القانونية (م)', 'السؤال', 'الإجابة'], dtype='object')\n",
            "عدد أزواج السؤال/الجواب بعد الدمج: 426\n",
            "عدد الصفوف بدون مادة مطابقة: 147\n",
            "\n",
            "========== Three-Shot Objective Metrics ==========\n",
            "Number of Three-Shot Q&A pairs: 426\n",
            "--------------------------------------------------\n",
            "Average Overlap Jaccard            : 0.132\n",
            "Average Coverage Answer in Article : 0.390\n",
            "\n",
            "تم حفظ الملف النظيف بدون أي Manual باسم: three_shot_metrics_clean.csv\n"
          ]
        }
      ]
    }
  ]
}